{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"promoter.ipynb","version":"0.3.2","provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nA_JVfzcORpJ","colab_type":"code","outputId":"02182030-f0c5-4189-8ac2-5b7f8504fd43","executionInfo":{"status":"ok","timestamp":1568025014284,"user_tz":-360,"elapsed":850,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qwoiwh4UObZ-","colab_type":"code","outputId":"084887e0-781f-4c46-fd9d-4d6000ae629f","executionInfo":{"status":"ok","timestamp":1568025024097,"user_tz":-360,"elapsed":6822,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#input_file = '/content/drive/My Drive/Study/T2/Bio/Project/Deep Learning with Python/maize_upreg_1000.fasta'\n","input_file = '/content/drive/My Drive/Deep Learning with Python/maize_upreg_1000.fasta'\n","handler = open(input_file,'r')\n","list_string=[]\n","y_train1 = []\n","sequence=\"\"\n","count=0\n","start_flag=False;\n","for string in handler:\n","    if(string[0]=='>'):\n","        start_flag=True;\n","        length=len(sequence)\n","        if(sequence!=\"\" and length>100):\n","            temp=0\n","            for char in sequence:\n","                if((char=='A' or char=='T' or char=='C' or char=='G')==False):\n","                    temp=1;\n","                    break\n","            if(temp==0):\n","                list_string.append(sequence)\n","                y_train1.append(0)\n","        sequence=\"\"\n","        count+=1\n","        continue\n","    if(start_flag==True):\n","        sequence+=string[0:len(string)-1]\n","    \n","        \n","#input_file = '/content/drive/My Drive/Study/T2/Bio/Project/Deep Learning with Python/maize_downreg_1000.fasta'\n","input_file = '/content/drive/My Drive/Deep Learning with Python/maize_downreg_1000.fasta'\n","handler = open(input_file,'r')\n","line=0;\n","sequence=\"\"\n","count=0\n","start_flag=False;\n","for string in handler:\n","    if(string[0]=='>'):\n","        start_flag=True;\n","        length=len(sequence)\n","        if(sequence!=\"\" and length>100):\n","            #print(length)\n","            temp=0\n","            for char in sequence:\n","                if((char=='A' or char=='T' or char=='C' or char=='G')==False):\n","                    temp=1;\n","                    break\n","            if(temp==0):\n","                list_string.append(sequence)\n","                y_train1.append(0)\n","        sequence=\"\"\n","        count+=1\n","        continue\n","    if(start_flag==True):\n","        sequence+=string[0:len(string)-1]\n","\n","    \n","        \n","stresslen= len(list_string)\n","#input_file = '/content/drive/My Drive/Study/T2/Bio/Project/Deep Learning with Python/maize_true_const_1000.fasta'\n","input_file = '/content/drive/My Drive/Deep Learning with Python/maize_true_const_1000.fasta'\n","handler = open(input_file,'r')\n","\n","line=0;\n","sequence=\"\"\n","count=0\n","start_flag=False;\n","for string in handler:\n","    if(string[0]=='>'):\n","        start_flag=True;\n","        length=len(sequence)\n","        if(sequence!=\"\" and length>100):\n","            #print(length)\n","            temp=0\n","            for char in sequence:\n","                if((char=='A' or char=='T' or char=='C' or char=='G')==False):\n","                    temp=1;\n","                    break\n","            if(temp==0):\n","                list_string.append(sequence)\n","                y_train1.append(1)\n","        sequence=\"\"\n","        count+=1\n","        continue\n","    if(start_flag==True):\n","        sequence+=string[0:len(string)-1]\n","#     if(len(list_string)==2*stresslen):\n","#         break;\n","constlen = len(list_string)        \n","print(constlen-stresslen)\n","print(stresslen)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["31532\n","9481\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z_aCQwbaPAG2","colab_type":"code","outputId":"39050b56-fbf6-487a-9575-c66394e48218","executionInfo":{"status":"ok","timestamp":1568025054261,"user_tz":-360,"elapsed":24288,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["maxlen = 1000\n","import numpy as np\n","x_train1 = np.zeros((len(list_string),maxlen))\n","i=0\n","for string in list_string:\n","  j=0\n","  for char in string:\n","    if(char=='A'):\n","      x_train1[i][j]=1\n","    if(char=='T'):\n","      x_train1[i][j]=2\n","    if(char=='C'):\n","      x_train1[i][j]=3\n","    if(char=='G'):\n","      x_train1[i][j]=4\n","    j=j+1\n","  i=i+1\n","print(len(list_string[0]))\n","print(x_train1.shape)\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["1000\n","(41013, 1000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RgXRcWi8cExe","colab_type":"code","outputId":"d4938df1-992e-4e3d-bc28-a41bcd9e5de1","executionInfo":{"status":"ok","timestamp":1568025073950,"user_tz":-360,"elapsed":892,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["y_train1 = np.array(y_train1)\n","\n","indices = np.arange(x_train1.shape[0])\n","np.random.shuffle(indices)\n","x_train1 = x_train1[indices]\n","y_train1 = y_train1[indices]\n","print(x_train1.shape)\n","print(y_train1.shape)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["(41013, 1000)\n","(41013,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9leWoUADPJLC","colab_type":"code","outputId":"c78ec5c8-b651-4b33-9033-d09ab384aa0d","executionInfo":{"status":"ok","timestamp":1568025077211,"user_tz":-360,"elapsed":1065,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_size = 2000\n","x_train = np.zeros((len(list_string)-2*val_size,maxlen))\n","y_train = np.random.rand(len(list_string)-2*val_size)\n","x_val = np.zeros((2*val_size,maxlen))\n","y_val = np.random.rand(2*val_size)\n","\n","j=0\n","k=0\n","l=0\n","m=0\n","for i in range(0,len(list_string)):\n","  if(y_train1[i]==0 and j<val_size):\n","    x_val[l]= x_train1[i]\n","    y_val[l]= 0\n","    j+=1\n","    l+=1\n","  elif(y_train1[i]==1 and k<val_size):\n","    x_val[l]= x_train1[i]\n","    y_val[l]= 1\n","    k+=1\n","    l+=1\n","  else:\n","    x_train[m]=x_train1[i]\n","    y_train[m]=y_train1[i]\n","    m+=1\n","\n","print(i,j,k,l,m)\n","    \n","    "],"execution_count":28,"outputs":[{"output_type":"stream","text":["41012 2000 2000 4000 37013\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Fn0A-khZvyx","colab_type":"code","outputId":"19980016-0729-4580-c2c6-6121ed03fe06","executionInfo":{"status":"ok","timestamp":1568025157136,"user_tz":-360,"elapsed":75878,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from collections import Counter\n","from sklearn.datasets import make_classification\n","from imblearn.over_sampling import SMOTE\n","print('Original dataset shape %s' % Counter(y_train))\n","sm = SMOTE(random_state=42)\n","x_train, y_train = sm.fit_resample(x_train, y_train)\n","print('Resampled dataset shape %s' % Counter(y_train))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Original dataset shape Counter({1.0: 29532, 0.0: 7481})\n","Resampled dataset shape Counter({1.0: 29532, 0.0: 29532})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TSvwaYLFgJjy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"62e94c88-5200-49d4-81ac-f430b0979f8e","executionInfo":{"status":"ok","timestamp":1568025226330,"user_tz":-360,"elapsed":864,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}}},"source":["import numpy as np\n","x_train = np.round(x_train)\n","\n","y_train = np.round(y_train)\n"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., ..., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"U3MKDHs2PUJa","colab_type":"code","outputId":"f6825a1a-7943-47b8-bc63-2a23f1cd4406","executionInfo":{"status":"ok","timestamp":1568025240914,"user_tz":-360,"elapsed":5042,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":989}},"source":["import numpy as np\n","from keras import Input\n","from keras.models import Sequential,Model\n","from keras.layers import Embedding, Flatten, Dense,LSTM,MaxPooling1D,Conv1D,Dropout,merge,Permute,Lambda,Reshape,RepeatVector,Multiply,Activation\n","from keras import layers\n","from keras import backend as K\n","max_words = 5\n","embedding_dim = 4\n","\n","units = 64\n","\n","#functional model\n","embedding_matrix=np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0]])\n","_input = Input(shape=[maxlen], dtype='int32')\n","embedded = Embedding(max_words,embedding_dim,input_length=maxlen,weights=[embedding_matrix],trainable=False)(_input)\n","#embedded = Reshape((250,units))(embedded)\n","conv1 = layers.Conv1D(16, 7, activation='relu')(embedded)\n","maxpool1 = layers.MaxPooling1D(2)(conv1)\n","conv2 = layers.Conv1D(32, 7, activation='relu')(maxpool1)\n","maxpool2 = layers.MaxPooling1D(2)(conv2)\n","conv3 = layers.Conv1D(64, 7, activation='relu')(maxpool2)\n","maxpool3 = layers.MaxPooling1D(2)(conv3)\n","lstm = LSTM(units,return_sequences=True)(maxpool3)\n","\n","attention = Dense(1, activation='tanh')(lstm)\n","attention = Flatten()(attention)\n","attention = Activation('softmax')(attention)\n","attention = RepeatVector(units)(attention)\n","attention = Permute([2, 1])(attention)\n","\n","sent_representation = Multiply()([lstm, attention])\n","sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units,))(sent_representation)\n","\n","# flat = Flatten()(embedded)\n","# dense0 = Dense(256, activation='relu')(flat)\n","# drop0 = Dropout(0.3)(dense0)\n","# dense = Dense(128, activation='relu')(drop0)\n","# drop = Dropout(0.3)(dense)\n","# dense1 = Dense(64, activation='relu')(drop)\n","# drop1 = Dropout(0.3)(dense1)\n","# dense2 = Dense(32, activation='relu')(drop1)\n","# drop2 = Dropout(0.3)(dense2)\n","# output1 = Dense(1, activation='sigmoid')(drop2)\n","output1 = Dense(1, activation='sigmoid')(sent_representation)\n","model = Model(input=_input, output=output1)\n","\n","#sequential model\n","# embedding_matrix=np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0]])\n","\n","# model = Sequential()\n","# model.add(Embedding(max_words, embedding_dim,input_length=maxlen))\n","# model.add(layers.Conv1D(16, 7, activation='relu'))\n","# model.add(layers.MaxPooling1D(2))\n","# model.add(layers.Conv1D(32, 7, activation='relu'))\n","# model.add(layers.MaxPooling1D(2))\n","# model.add(layers.Conv1D(64, 7, activation='relu'))\n","# model.add(LSTM(64))\n","# # model.add(LSTM(64,return_sequences=True))\n","# # model.add(layers.MaxPooling1D(3))\n","# # model.add(Flatten())\n","# # model.add(Dense(64, activation='relu'))\n","# # model.add(Dropout(0.3))\n","# model.add(Dense(16, activation='relu'))\n","# model.add(Dropout(0.3))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","# model.layers[0].set_weights([embedding_matrix])\n","# model.layers[0].trainable = False\n","\n","\n","model.summary()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1000, 4)      20          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 994, 16)      464         embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","max_pooling1d_1 (MaxPooling1D)  (None, 497, 16)      0           conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 491, 32)      3616        max_pooling1d_1[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling1d_2 (MaxPooling1D)  (None, 245, 32)      0           conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 239, 64)      14400       max_pooling1d_2[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling1d_3 (MaxPooling1D)  (None, 119, 64)      0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   (None, 119, 64)      33024       max_pooling1d_3[0][0]            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 119, 1)       65          lstm_1[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 119)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 119)          0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 64, 119)      0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","permute_1 (Permute)             (None, 119, 64)      0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 119, 64)      0           lstm_1[0][0]                     \n","                                                                 permute_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 64)           0           multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            65          lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 51,654\n","Trainable params: 51,634\n","Non-trainable params: 20\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mHTz1INuQOoh","colab_type":"code","outputId":"f0125ab0-7c7a-4d14-a215-b7038d2a3a14","executionInfo":{"status":"ok","timestamp":1568036510388,"user_tz":-360,"elapsed":11257893,"user":{"displayName":"Hasan Murad student","photoUrl":"","userId":"14257210307993081342"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(optimizer='adam',\n","loss='binary_crossentropy',\n","metrics=['acc'])\n","history = model.fit(x_train, y_train,\n","                    epochs=200,\n","#                     batch_size=256,validation_split =.1)\n","                      batch_size=256,validation_data =(x_val,y_val))\n","#model.save('/content/drive/My Drive/Study/T2/Bio/Project/Deep Learning with Python/my_model.h5')\n","model.save('/content/drive/My Drive/Deep Learning with Python/my_model_19_8.h5')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 59064 samples, validate on 4000 samples\n","Epoch 1/200\n","59064/59064 [==============================] - 61s 1ms/step - loss: 0.6003 - acc: 0.6346 - val_loss: 0.7195 - val_acc: 0.5030\n","Epoch 2/200\n","59064/59064 [==============================] - 57s 960us/step - loss: 0.5845 - acc: 0.6493 - val_loss: 0.7173 - val_acc: 0.5005\n","Epoch 3/200\n","59064/59064 [==============================] - 57s 966us/step - loss: 0.5822 - acc: 0.6513 - val_loss: 0.7173 - val_acc: 0.5048\n","Epoch 4/200\n","59064/59064 [==============================] - 57s 965us/step - loss: 0.5798 - acc: 0.6547 - val_loss: 0.7141 - val_acc: 0.5048\n","Epoch 5/200\n","59064/59064 [==============================] - 57s 961us/step - loss: 0.5762 - acc: 0.6573 - val_loss: 0.6977 - val_acc: 0.5150\n","Epoch 6/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.5713 - acc: 0.6635 - val_loss: 0.7175 - val_acc: 0.5198\n","Epoch 7/200\n","59064/59064 [==============================] - 56s 957us/step - loss: 0.5683 - acc: 0.6687 - val_loss: 0.6935 - val_acc: 0.5353\n","Epoch 8/200\n","59064/59064 [==============================] - 57s 968us/step - loss: 0.5582 - acc: 0.6846 - val_loss: 0.7269 - val_acc: 0.5455\n","Epoch 9/200\n","59064/59064 [==============================] - 57s 959us/step - loss: 0.5394 - acc: 0.7051 - val_loss: 0.6824 - val_acc: 0.5817\n","Epoch 10/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.5128 - acc: 0.7340 - val_loss: 0.6543 - val_acc: 0.6155\n","Epoch 11/200\n","59064/59064 [==============================] - 57s 965us/step - loss: 0.4717 - acc: 0.7687 - val_loss: 0.6427 - val_acc: 0.6370\n","Epoch 12/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.4378 - acc: 0.7954 - val_loss: 0.6343 - val_acc: 0.6758\n","Epoch 13/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.4018 - acc: 0.8218 - val_loss: 0.6436 - val_acc: 0.6775\n","Epoch 14/200\n","59064/59064 [==============================] - 57s 963us/step - loss: 0.3669 - acc: 0.8457 - val_loss: 0.5909 - val_acc: 0.7138\n","Epoch 15/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.3349 - acc: 0.8645 - val_loss: 0.5894 - val_acc: 0.7275\n","Epoch 16/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.3129 - acc: 0.8777 - val_loss: 0.6024 - val_acc: 0.7292\n","Epoch 17/200\n","59064/59064 [==============================] - 57s 965us/step - loss: 0.2924 - acc: 0.8880 - val_loss: 0.5741 - val_acc: 0.7418\n","Epoch 18/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.2743 - acc: 0.8962 - val_loss: 0.5813 - val_acc: 0.7510\n","Epoch 19/200\n","59064/59064 [==============================] - 57s 968us/step - loss: 0.2630 - acc: 0.9026 - val_loss: 0.5926 - val_acc: 0.7533\n","Epoch 20/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.2537 - acc: 0.9061 - val_loss: 0.6915 - val_acc: 0.7243\n","Epoch 21/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.2440 - acc: 0.9111 - val_loss: 0.5908 - val_acc: 0.7630\n","Epoch 22/200\n","59064/59064 [==============================] - 57s 964us/step - loss: 0.2262 - acc: 0.9186 - val_loss: 0.5708 - val_acc: 0.7708\n","Epoch 23/200\n","59064/59064 [==============================] - 57s 960us/step - loss: 0.2202 - acc: 0.9212 - val_loss: 0.6349 - val_acc: 0.7645\n","Epoch 24/200\n","59064/59064 [==============================] - 57s 959us/step - loss: 0.2154 - acc: 0.9246 - val_loss: 0.5591 - val_acc: 0.7780\n","Epoch 25/200\n","59064/59064 [==============================] - 57s 965us/step - loss: 0.2010 - acc: 0.9303 - val_loss: 0.6039 - val_acc: 0.7745\n","Epoch 26/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.1958 - acc: 0.9325 - val_loss: 0.6299 - val_acc: 0.7663\n","Epoch 27/200\n","59064/59064 [==============================] - 57s 959us/step - loss: 0.1875 - acc: 0.9354 - val_loss: 0.6082 - val_acc: 0.7890\n","Epoch 28/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.1745 - acc: 0.9420 - val_loss: 0.5892 - val_acc: 0.7855\n","Epoch 29/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.1729 - acc: 0.9424 - val_loss: 0.5951 - val_acc: 0.7893\n","Epoch 30/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.1749 - acc: 0.9405 - val_loss: 0.6156 - val_acc: 0.7865\n","Epoch 31/200\n","59064/59064 [==============================] - 56s 945us/step - loss: 0.1572 - acc: 0.9483 - val_loss: 0.6490 - val_acc: 0.7798\n","Epoch 32/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.1587 - acc: 0.9483 - val_loss: 0.6246 - val_acc: 0.7935\n","Epoch 33/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.1559 - acc: 0.9483 - val_loss: 0.6815 - val_acc: 0.7768\n","Epoch 34/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.1486 - acc: 0.9509 - val_loss: 0.6194 - val_acc: 0.7958\n","Epoch 35/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.1456 - acc: 0.9521 - val_loss: 0.6712 - val_acc: 0.7900\n","Epoch 36/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.1401 - acc: 0.9541 - val_loss: 0.6707 - val_acc: 0.7815\n","Epoch 37/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.1382 - acc: 0.9550 - val_loss: 0.6752 - val_acc: 0.7890\n","Epoch 38/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.1335 - acc: 0.9572 - val_loss: 0.5826 - val_acc: 0.8065\n","Epoch 39/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.1344 - acc: 0.9564 - val_loss: 0.6007 - val_acc: 0.8018\n","Epoch 40/200\n","59064/59064 [==============================] - 56s 943us/step - loss: 0.1282 - acc: 0.9586 - val_loss: 0.5954 - val_acc: 0.8010\n","Epoch 41/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.1239 - acc: 0.9597 - val_loss: 0.6572 - val_acc: 0.8072\n","Epoch 42/200\n","59064/59064 [==============================] - 56s 945us/step - loss: 0.1319 - acc: 0.9566 - val_loss: 0.6122 - val_acc: 0.8025\n","Epoch 43/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.1172 - acc: 0.9631 - val_loss: 0.6558 - val_acc: 0.8043\n","Epoch 44/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.1173 - acc: 0.9624 - val_loss: 0.6660 - val_acc: 0.8037\n","Epoch 45/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.1243 - acc: 0.9592 - val_loss: 0.6374 - val_acc: 0.8035\n","Epoch 46/200\n","59064/59064 [==============================] - 56s 942us/step - loss: 0.1171 - acc: 0.9614 - val_loss: 0.6297 - val_acc: 0.8137\n","Epoch 47/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.1094 - acc: 0.9644 - val_loss: 0.6367 - val_acc: 0.8085\n","Epoch 48/200\n","59064/59064 [==============================] - 56s 945us/step - loss: 0.1094 - acc: 0.9643 - val_loss: 0.6460 - val_acc: 0.8072\n","Epoch 49/200\n","59064/59064 [==============================] - 57s 961us/step - loss: 0.1035 - acc: 0.9668 - val_loss: 0.7007 - val_acc: 0.8095\n","Epoch 50/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.1061 - acc: 0.9659 - val_loss: 0.6976 - val_acc: 0.8123\n","Epoch 51/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.1012 - acc: 0.9670 - val_loss: 0.6965 - val_acc: 0.8120\n","Epoch 52/200\n","59064/59064 [==============================] - 57s 963us/step - loss: 0.1069 - acc: 0.9649 - val_loss: 0.6305 - val_acc: 0.8103\n","Epoch 53/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.1123 - acc: 0.9626 - val_loss: 0.7011 - val_acc: 0.8123\n","Epoch 54/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.1020 - acc: 0.9660 - val_loss: 0.6966 - val_acc: 0.8127\n","Epoch 55/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0951 - acc: 0.9688 - val_loss: 0.7494 - val_acc: 0.8040\n","Epoch 56/200\n","59064/59064 [==============================] - 57s 962us/step - loss: 0.0942 - acc: 0.9693 - val_loss: 0.6852 - val_acc: 0.8108\n","Epoch 57/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.1005 - acc: 0.9665 - val_loss: 0.7016 - val_acc: 0.8130\n","Epoch 58/200\n","59064/59064 [==============================] - 57s 968us/step - loss: 0.0946 - acc: 0.9686 - val_loss: 0.6147 - val_acc: 0.8133\n","Epoch 59/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.0947 - acc: 0.9680 - val_loss: 0.7142 - val_acc: 0.8120\n","Epoch 60/200\n","59064/59064 [==============================] - 57s 961us/step - loss: 0.0877 - acc: 0.9707 - val_loss: 0.6610 - val_acc: 0.8165\n","Epoch 61/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0866 - acc: 0.9714 - val_loss: 0.7574 - val_acc: 0.8055\n","Epoch 62/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0856 - acc: 0.9722 - val_loss: 0.6918 - val_acc: 0.8143\n","Epoch 63/200\n","59064/59064 [==============================] - 57s 962us/step - loss: 0.0871 - acc: 0.9709 - val_loss: 0.7057 - val_acc: 0.8122\n","Epoch 64/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0869 - acc: 0.9712 - val_loss: 0.7363 - val_acc: 0.8145\n","Epoch 65/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.0863 - acc: 0.9712 - val_loss: 0.7007 - val_acc: 0.8180\n","Epoch 66/200\n","59064/59064 [==============================] - 57s 959us/step - loss: 0.0801 - acc: 0.9736 - val_loss: 0.6847 - val_acc: 0.8187\n","Epoch 67/200\n","59064/59064 [==============================] - 56s 945us/step - loss: 0.0847 - acc: 0.9711 - val_loss: 0.6623 - val_acc: 0.8147\n","Epoch 68/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0837 - acc: 0.9720 - val_loss: 0.7810 - val_acc: 0.8067\n","Epoch 69/200\n","59064/59064 [==============================] - 56s 957us/step - loss: 0.0834 - acc: 0.9717 - val_loss: 0.6344 - val_acc: 0.8240\n","Epoch 70/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0768 - acc: 0.9745 - val_loss: 0.7110 - val_acc: 0.8138\n","Epoch 71/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0781 - acc: 0.9736 - val_loss: 0.7079 - val_acc: 0.8170\n","Epoch 72/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0837 - acc: 0.9716 - val_loss: 0.7086 - val_acc: 0.8163\n","Epoch 73/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0746 - acc: 0.9746 - val_loss: 0.7150 - val_acc: 0.8237\n","Epoch 74/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0704 - acc: 0.9769 - val_loss: 0.7335 - val_acc: 0.8240\n","Epoch 75/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0807 - acc: 0.9716 - val_loss: 0.7987 - val_acc: 0.8135\n","Epoch 76/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0703 - acc: 0.9756 - val_loss: 0.7393 - val_acc: 0.8195\n","Epoch 77/200\n","59064/59064 [==============================] - 56s 944us/step - loss: 0.0679 - acc: 0.9775 - val_loss: 0.7764 - val_acc: 0.8070\n","Epoch 78/200\n","59064/59064 [==============================] - 56s 944us/step - loss: 0.0732 - acc: 0.9748 - val_loss: 0.7981 - val_acc: 0.8190\n","Epoch 79/200\n","59064/59064 [==============================] - 56s 943us/step - loss: 0.0698 - acc: 0.9757 - val_loss: 0.6548 - val_acc: 0.8255\n","Epoch 80/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0687 - acc: 0.9760 - val_loss: 0.7214 - val_acc: 0.8160\n","Epoch 81/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0735 - acc: 0.9744 - val_loss: 0.7874 - val_acc: 0.8130\n","Epoch 82/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0672 - acc: 0.9767 - val_loss: 0.7414 - val_acc: 0.8240\n","Epoch 83/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0641 - acc: 0.9773 - val_loss: 0.8407 - val_acc: 0.8085\n","Epoch 84/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0658 - acc: 0.9767 - val_loss: 0.7696 - val_acc: 0.8173\n","Epoch 85/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0689 - acc: 0.9756 - val_loss: 0.6638 - val_acc: 0.8217\n","Epoch 86/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0692 - acc: 0.9758 - val_loss: 0.7494 - val_acc: 0.8180\n","Epoch 87/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0604 - acc: 0.9784 - val_loss: 0.7700 - val_acc: 0.8215\n","Epoch 88/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0669 - acc: 0.9765 - val_loss: 0.7821 - val_acc: 0.8150\n","Epoch 89/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0636 - acc: 0.9775 - val_loss: 0.6988 - val_acc: 0.8295\n","Epoch 90/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0682 - acc: 0.9758 - val_loss: 0.8352 - val_acc: 0.8130\n","Epoch 91/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.0713 - acc: 0.9748 - val_loss: 0.6886 - val_acc: 0.8175\n","Epoch 92/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0643 - acc: 0.9773 - val_loss: 0.7471 - val_acc: 0.8250\n","Epoch 93/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0605 - acc: 0.9782 - val_loss: 0.7272 - val_acc: 0.8302\n","Epoch 94/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0647 - acc: 0.9768 - val_loss: 0.7262 - val_acc: 0.8238\n","Epoch 95/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0685 - acc: 0.9759 - val_loss: 0.7463 - val_acc: 0.8220\n","Epoch 96/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0653 - acc: 0.9765 - val_loss: 0.7157 - val_acc: 0.8242\n","Epoch 97/200\n","59064/59064 [==============================] - 57s 962us/step - loss: 0.0656 - acc: 0.9763 - val_loss: 0.8341 - val_acc: 0.8150\n","Epoch 98/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0817 - acc: 0.9705 - val_loss: 0.7616 - val_acc: 0.8242\n","Epoch 99/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0652 - acc: 0.9758 - val_loss: 0.6748 - val_acc: 0.8297\n","Epoch 100/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0546 - acc: 0.9796 - val_loss: 0.7629 - val_acc: 0.8260\n","Epoch 101/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0521 - acc: 0.9806 - val_loss: 0.7606 - val_acc: 0.8272\n","Epoch 102/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0939 - acc: 0.9659 - val_loss: 0.7427 - val_acc: 0.8268\n","Epoch 103/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0552 - acc: 0.9802 - val_loss: 0.7645 - val_acc: 0.8325\n","Epoch 104/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0513 - acc: 0.9817 - val_loss: 0.7786 - val_acc: 0.8290\n","Epoch 105/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.0555 - acc: 0.9797 - val_loss: 0.8763 - val_acc: 0.8225\n","Epoch 106/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0528 - acc: 0.9800 - val_loss: 0.8328 - val_acc: 0.8270\n","Epoch 107/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0602 - acc: 0.9777 - val_loss: 0.8448 - val_acc: 0.8218\n","Epoch 108/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0566 - acc: 0.9790 - val_loss: 0.7557 - val_acc: 0.8285\n","Epoch 109/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0484 - acc: 0.9819 - val_loss: 0.8254 - val_acc: 0.8267\n","Epoch 110/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0573 - acc: 0.9778 - val_loss: 0.7130 - val_acc: 0.8293\n","Epoch 111/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0556 - acc: 0.9792 - val_loss: 0.7692 - val_acc: 0.8275\n","Epoch 112/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0588 - acc: 0.9780 - val_loss: 0.8558 - val_acc: 0.8205\n","Epoch 113/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0542 - acc: 0.9800 - val_loss: 0.8617 - val_acc: 0.8262\n","Epoch 114/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0566 - acc: 0.9786 - val_loss: 0.8450 - val_acc: 0.8210\n","Epoch 115/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0576 - acc: 0.9784 - val_loss: 0.8422 - val_acc: 0.8228\n","Epoch 116/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0545 - acc: 0.9795 - val_loss: 0.9016 - val_acc: 0.8080\n","Epoch 117/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0587 - acc: 0.9781 - val_loss: 0.8514 - val_acc: 0.8207\n","Epoch 118/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0494 - acc: 0.9815 - val_loss: 0.8830 - val_acc: 0.8277\n","Epoch 119/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.0513 - acc: 0.9805 - val_loss: 0.7895 - val_acc: 0.8245\n","Epoch 120/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0608 - acc: 0.9772 - val_loss: 0.7267 - val_acc: 0.8242\n","Epoch 121/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0534 - acc: 0.9796 - val_loss: 0.8323 - val_acc: 0.8260\n","Epoch 122/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0496 - acc: 0.9814 - val_loss: 0.9305 - val_acc: 0.8207\n","Epoch 123/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0467 - acc: 0.9820 - val_loss: 0.8338 - val_acc: 0.8305\n","Epoch 124/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0631 - acc: 0.9760 - val_loss: 0.8739 - val_acc: 0.8175\n","Epoch 125/200\n","59064/59064 [==============================] - 56s 956us/step - loss: 0.0481 - acc: 0.9817 - val_loss: 0.8078 - val_acc: 0.8300\n","Epoch 126/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0563 - acc: 0.9791 - val_loss: 0.8206 - val_acc: 0.8302\n","Epoch 127/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0539 - acc: 0.9797 - val_loss: 0.7473 - val_acc: 0.8240\n","Epoch 128/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0564 - acc: 0.9795 - val_loss: 0.8131 - val_acc: 0.8265\n","Epoch 129/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0616 - acc: 0.9768 - val_loss: 0.9169 - val_acc: 0.8233\n","Epoch 130/200\n","59064/59064 [==============================] - 57s 963us/step - loss: 0.0530 - acc: 0.9801 - val_loss: 0.7824 - val_acc: 0.8298\n","Epoch 131/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0504 - acc: 0.9804 - val_loss: 0.8337 - val_acc: 0.8300\n","Epoch 132/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.0481 - acc: 0.9815 - val_loss: 0.8396 - val_acc: 0.8330\n","Epoch 133/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0498 - acc: 0.9812 - val_loss: 0.8192 - val_acc: 0.8193\n","Epoch 134/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0505 - acc: 0.9802 - val_loss: 0.8573 - val_acc: 0.8245\n","Epoch 135/200\n","59064/59064 [==============================] - 57s 959us/step - loss: 0.0499 - acc: 0.9807 - val_loss: 0.8424 - val_acc: 0.8308\n","Epoch 136/200\n","59064/59064 [==============================] - 55s 932us/step - loss: 0.0479 - acc: 0.9814 - val_loss: 0.7688 - val_acc: 0.8347\n","Epoch 137/200\n","59064/59064 [==============================] - 54s 919us/step - loss: 0.0451 - acc: 0.9817 - val_loss: 0.8910 - val_acc: 0.8215\n","Epoch 138/200\n","59064/59064 [==============================] - 55s 923us/step - loss: 0.0608 - acc: 0.9769 - val_loss: 0.8416 - val_acc: 0.8290\n","Epoch 139/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.0449 - acc: 0.9824 - val_loss: 0.9057 - val_acc: 0.8270\n","Epoch 140/200\n","59064/59064 [==============================] - 55s 938us/step - loss: 0.0464 - acc: 0.9815 - val_loss: 0.7744 - val_acc: 0.8275\n","Epoch 141/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0502 - acc: 0.9805 - val_loss: 0.8798 - val_acc: 0.8230\n","Epoch 142/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0553 - acc: 0.9792 - val_loss: 0.8441 - val_acc: 0.8225\n","Epoch 143/200\n","59064/59064 [==============================] - 56s 944us/step - loss: 0.0497 - acc: 0.9811 - val_loss: 0.8720 - val_acc: 0.8275\n","Epoch 144/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.0489 - acc: 0.9808 - val_loss: 0.9011 - val_acc: 0.8225\n","Epoch 145/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0527 - acc: 0.9791 - val_loss: 0.7570 - val_acc: 0.8230\n","Epoch 146/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0493 - acc: 0.9806 - val_loss: 0.9190 - val_acc: 0.8220\n","Epoch 147/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0446 - acc: 0.9822 - val_loss: 0.8680 - val_acc: 0.8270\n","Epoch 148/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0423 - acc: 0.9829 - val_loss: 0.9357 - val_acc: 0.8252\n","Epoch 149/200\n","59064/59064 [==============================] - 56s 944us/step - loss: 0.0443 - acc: 0.9824 - val_loss: 0.9114 - val_acc: 0.8265\n","Epoch 150/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0541 - acc: 0.9789 - val_loss: 1.0138 - val_acc: 0.8123\n","Epoch 151/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0488 - acc: 0.9811 - val_loss: 0.8784 - val_acc: 0.8235\n","Epoch 152/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0492 - acc: 0.9808 - val_loss: 0.8632 - val_acc: 0.8195\n","Epoch 153/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0558 - acc: 0.9787 - val_loss: 0.8235 - val_acc: 0.8275\n","Epoch 154/200\n","59064/59064 [==============================] - 56s 943us/step - loss: 0.0500 - acc: 0.9804 - val_loss: 0.8056 - val_acc: 0.8198\n","Epoch 155/200\n","59064/59064 [==============================] - 56s 942us/step - loss: 0.0478 - acc: 0.9814 - val_loss: 0.8716 - val_acc: 0.8280\n","Epoch 156/200\n","59064/59064 [==============================] - 56s 942us/step - loss: 0.0446 - acc: 0.9822 - val_loss: 0.9580 - val_acc: 0.8190\n","Epoch 157/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0437 - acc: 0.9826 - val_loss: 0.8821 - val_acc: 0.8258\n","Epoch 158/200\n","59064/59064 [==============================] - 56s 943us/step - loss: 0.0466 - acc: 0.9817 - val_loss: 0.9331 - val_acc: 0.8275\n","Epoch 159/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0428 - acc: 0.9827 - val_loss: 0.7471 - val_acc: 0.8330\n","Epoch 160/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.0528 - acc: 0.9796 - val_loss: 0.8924 - val_acc: 0.8202\n","Epoch 161/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0481 - acc: 0.9813 - val_loss: 0.9327 - val_acc: 0.8225\n","Epoch 162/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0516 - acc: 0.9798 - val_loss: 0.9484 - val_acc: 0.8190\n","Epoch 163/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0496 - acc: 0.9805 - val_loss: 0.8759 - val_acc: 0.8285\n","Epoch 164/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0410 - acc: 0.9828 - val_loss: 0.9398 - val_acc: 0.8237\n","Epoch 165/200\n","59064/59064 [==============================] - 56s 944us/step - loss: 0.0469 - acc: 0.9811 - val_loss: 0.8553 - val_acc: 0.8260\n","Epoch 166/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0513 - acc: 0.9799 - val_loss: 0.9138 - val_acc: 0.8250\n","Epoch 167/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0451 - acc: 0.9817 - val_loss: 0.9117 - val_acc: 0.8230\n","Epoch 168/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0446 - acc: 0.9819 - val_loss: 0.8828 - val_acc: 0.8260\n","Epoch 169/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.0440 - acc: 0.9821 - val_loss: 0.9317 - val_acc: 0.8255\n","Epoch 170/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0439 - acc: 0.9821 - val_loss: 0.9513 - val_acc: 0.8185\n","Epoch 171/200\n","59064/59064 [==============================] - 56s 949us/step - loss: 0.0477 - acc: 0.9803 - val_loss: 0.8767 - val_acc: 0.8255\n","Epoch 172/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0488 - acc: 0.9804 - val_loss: 0.8943 - val_acc: 0.8245\n","Epoch 173/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0507 - acc: 0.9797 - val_loss: 0.7977 - val_acc: 0.8228\n","Epoch 174/200\n","59064/59064 [==============================] - 57s 965us/step - loss: 0.0438 - acc: 0.9821 - val_loss: 0.8580 - val_acc: 0.8288\n","Epoch 175/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0389 - acc: 0.9834 - val_loss: 0.9192 - val_acc: 0.8295\n","Epoch 176/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0405 - acc: 0.9833 - val_loss: 0.9188 - val_acc: 0.8262\n","Epoch 177/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0406 - acc: 0.9828 - val_loss: 0.8832 - val_acc: 0.8250\n","Epoch 178/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0568 - acc: 0.9771 - val_loss: 0.8624 - val_acc: 0.8212\n","Epoch 179/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0508 - acc: 0.9802 - val_loss: 0.8369 - val_acc: 0.8305\n","Epoch 180/200\n","59064/59064 [==============================] - 57s 962us/step - loss: 0.0452 - acc: 0.9815 - val_loss: 0.9230 - val_acc: 0.8277\n","Epoch 181/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0421 - acc: 0.9823 - val_loss: 0.9769 - val_acc: 0.8267\n","Epoch 182/200\n","59064/59064 [==============================] - 56s 943us/step - loss: 0.0443 - acc: 0.9819 - val_loss: 0.9637 - val_acc: 0.8278\n","Epoch 183/200\n","59064/59064 [==============================] - 56s 944us/step - loss: 0.0424 - acc: 0.9826 - val_loss: 0.8656 - val_acc: 0.8303\n","Epoch 184/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0431 - acc: 0.9825 - val_loss: 0.9404 - val_acc: 0.8240\n","Epoch 185/200\n","59064/59064 [==============================] - 57s 960us/step - loss: 0.0451 - acc: 0.9815 - val_loss: 0.9070 - val_acc: 0.8302\n","Epoch 186/200\n","59064/59064 [==============================] - 56s 946us/step - loss: 0.0504 - acc: 0.9795 - val_loss: 0.8147 - val_acc: 0.8292\n","Epoch 187/200\n","59064/59064 [==============================] - 56s 945us/step - loss: 0.0449 - acc: 0.9816 - val_loss: 0.8806 - val_acc: 0.8278\n","Epoch 188/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0435 - acc: 0.9821 - val_loss: 0.9232 - val_acc: 0.8290\n","Epoch 189/200\n","59064/59064 [==============================] - 56s 947us/step - loss: 0.0390 - acc: 0.9840 - val_loss: 0.9687 - val_acc: 0.8263\n","Epoch 190/200\n","59064/59064 [==============================] - 56s 948us/step - loss: 0.0402 - acc: 0.9827 - val_loss: 1.0072 - val_acc: 0.8273\n","Epoch 191/200\n","59064/59064 [==============================] - 57s 958us/step - loss: 0.0474 - acc: 0.9807 - val_loss: 0.9245 - val_acc: 0.8170\n","Epoch 192/200\n","59064/59064 [==============================] - 56s 950us/step - loss: 0.0431 - acc: 0.9821 - val_loss: 0.8060 - val_acc: 0.8312\n","Epoch 193/200\n","59064/59064 [==============================] - 56s 951us/step - loss: 0.0402 - acc: 0.9831 - val_loss: 0.9974 - val_acc: 0.8268\n","Epoch 194/200\n","59064/59064 [==============================] - 56s 954us/step - loss: 0.0469 - acc: 0.9808 - val_loss: 0.9924 - val_acc: 0.8200\n","Epoch 195/200\n","59064/59064 [==============================] - 56s 952us/step - loss: 0.0502 - acc: 0.9802 - val_loss: 0.8361 - val_acc: 0.8313\n","Epoch 196/200\n","59064/59064 [==============================] - 57s 963us/step - loss: 0.0438 - acc: 0.9820 - val_loss: 1.0811 - val_acc: 0.8098\n","Epoch 197/200\n","59064/59064 [==============================] - 57s 957us/step - loss: 0.0442 - acc: 0.9819 - val_loss: 0.9657 - val_acc: 0.8260\n","Epoch 198/200\n","59064/59064 [==============================] - 56s 955us/step - loss: 0.0445 - acc: 0.9819 - val_loss: 0.9250 - val_acc: 0.8255\n","Epoch 199/200\n","59064/59064 [==============================] - 56s 957us/step - loss: 0.0420 - acc: 0.9828 - val_loss: 0.9842 - val_acc: 0.8223\n","Epoch 200/200\n","59064/59064 [==============================] - 56s 953us/step - loss: 0.0405 - acc: 0.9833 - val_loss: 0.9731 - val_acc: 0.8210\n"],"name":"stdout"}]}]}